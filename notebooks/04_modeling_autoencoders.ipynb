{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d786c9fd-44e3-415e-b0dd-bb8f1c32d911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3561/3561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.8711 - val_loss: 0.7389\n",
      "Epoch 2/10\n",
      "\u001b[1m3561/3561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7395 - val_loss: 0.7233\n",
      "Epoch 3/10\n",
      "\u001b[1m3561/3561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7342 - val_loss: 0.7184\n",
      "Epoch 4/10\n",
      "\u001b[1m3561/3561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7215 - val_loss: 0.7162\n",
      "Epoch 5/10\n",
      "\u001b[1m3561/3561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7174 - val_loss: 0.7144\n",
      "Epoch 6/10\n",
      "\u001b[1m3561/3561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7173 - val_loss: 0.7120\n",
      "Epoch 7/10\n",
      "\u001b[1m3561/3561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7022 - val_loss: 0.7107\n",
      "Epoch 8/10\n",
      "\u001b[1m3561/3561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7184 - val_loss: 0.7090\n",
      "Epoch 9/10\n",
      "\u001b[1m3561/3561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.7224 - val_loss: 0.7082\n",
      "Epoch 10/10\n",
      "\u001b[1m3561/3561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.7170 - val_loss: 0.7081\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 536us/step\n",
      "\u001b[1m8901/8901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 527us/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97    284315\n",
      "           1       0.03      0.87      0.06       492\n",
      "\n",
      "    accuracy                           0.95    284807\n",
      "   macro avg       0.51      0.91      0.52    284807\n",
      "weighted avg       1.00      0.95      0.97    284807\n",
      "\n",
      "Accuracy: 0.9512827985267216\n",
      "Modeling with Autoencoders completed and model saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "data = pd.read_csv('../data/processed_data.csv')\n",
    "X = data.drop(columns=['Class']).values\n",
    "y = data['Class'].values\n",
    "\n",
    "# Define the autoencoder architecture using Functional API\n",
    "input_dim = X.shape[1]\n",
    "input_layer = keras.Input(shape=(input_dim,))\n",
    "encoded = layers.Dense(32, activation='relu')(input_layer)\n",
    "encoded = layers.Dense(16, activation='relu')(encoded)\n",
    "decoded = layers.Dense(32, activation='relu')(encoded)\n",
    "decoded = layers.Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = keras.Model(inputs=input_layer, outputs=decoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X, X, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Extract the encoder part\n",
    "encoder = keras.Model(inputs=input_layer, outputs=encoded)\n",
    "encoded_X = encoder.predict(X)\n",
    "\n",
    "# Reconstruction error\n",
    "reconstructed_X = autoencoder.predict(X)\n",
    "reconstruction_error = np.mean(np.power(X - reconstructed_X, 2), axis=1)\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold = np.percentile(reconstruction_error, 95)\n",
    "predictions = (reconstruction_error > threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y, predictions))\n",
    "print(\"Accuracy:\", accuracy_score(y, predictions))\n",
    "\n",
    "# Save the autoencoder model\n",
    "autoencoder.save('../models/autoencoder_model.keras')\n",
    "\n",
    "print(\"Modeling with Autoencoders completed and model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93718c51-da2c-4e1e-a541-218d5f3a1f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
